{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force-based human's intent recognition: Raw-data-based classification\n",
    "\n",
    "In this approach, using directly the data obtained from the sensor, the classification is done by means of a k-Nearest Neighbors (kNN) classifier with Dynamic Time Warping (DTW)[1] as metric. Particularly, we have used $k = 1$. \n",
    "\n",
    "Dynamic Time Warping is a time-dependent algorithm used to measure similarity between two temporal sequences which may vary in speed. For instance, similarities in polishing could be detected using DTW, even if the operator polishes faster or slower than in other occasions. DTW is a computational intense technique (quadratic time and memory complexity), however, there are some ways to accelerate its computation. In our case, we use the library Fast DTW[2].\n",
    "DTW is meant to be utilized for uni-variate time series, which is not our case, since we have six sensor's axes. From the literature, we know at least two obvious approaches to tackle this and generalize DTW for multi-dimensional time series: *dependent* and *independent* DTW[3]. \n",
    "kNN classifier is taken from \\textit{scikit learn} library. Since default implementations of both, kNN and Fast DTW, do not allow to work with multi-dimensional time series, it was necessary to adapt the used libraries. Apart from those modifications, we used the values set by default.\n",
    "\n",
    "#### Note\n",
    "In this notebook, you can train your classifier with cross validation without replacement and evaluate the results. Please, if you want to do the training with a pre-defined dataset and generate a final model, go to the another notebook of this folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.utils_general import *\n",
    "from scripts.utils_evaluation import *\n",
    "from scripts.utils_data_process import *\n",
    "from scripts.utils_evaluation_global_variables import *\n",
    "\n",
    "# headers dtw\n",
    "from fastdtw._fastdtw import fastdtw \n",
    "from scipy.spatial.distance import euclidean\n",
    "from scripts.kNN_wrapper import KNeighborsClassifierWrapper\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, mean_squared_error, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for processing the data\n",
    "type_of_dataset = 'natural' # natural or mechanical\n",
    "labels = {0:'grab', 1:'move', 2:'polish'}\n",
    "dataset_folder = '../data/'\n",
    "\n",
    "training_portion = 0.75\n",
    "\n",
    "\n",
    "# parameters for data length\n",
    "number_of_measurements = 350 # size of the window\n",
    "final_signal_size_percentage = 0.02 # percentage of the total signal which is kept after subsampling\n",
    "step = int(round(1/final_signal_size_percentage)) # for subsampling\n",
    "\n",
    "\n",
    "# multi-dimensional DTW\n",
    "dtw_d = lambda a, b: sum((a - b) ** 2) ** 0.5\n",
    "dtw_i = lambda a, b: sum(((a - b) ** 2) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# used metrics\n",
    "def fastdtw_multivariate(x_, y_, dist_):\n",
    "    distance = fastdtw(x_, y_, dist=dist_)[0]\n",
    "    return distance\n",
    "\n",
    "# dtw metrics\n",
    "dtw_d_metric_ = lambda a, b: fastdtw_multivariate(a, b, dist_=dtw_d)\n",
    "dtw_i_metric_ = lambda a, b: fastdtw_multivariate(a, b, dist_=dtw_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = read_dataset_(dataset_folder, type_of_dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loop_evaluations = 1\n",
    "\n",
    "for i in range (0, loop_evaluations):\n",
    "    \n",
    "    \n",
    "    data_training, data_test = pick_training_dataset_randomly_(processed_data, training_portion, \\\n",
    "                                                               number_of_measurements, step, normalize=False)\n",
    "    #\"\"\"\n",
    "    # dependent DTW\n",
    "    print \"------ DTW d\", i\n",
    "    neighbors = 9\n",
    "    metric_name_to_use_ = 'fastDTW'\n",
    "\n",
    "    knn_dependent_dtw_ = KNeighborsClassifierWrapper(n_neighbors=neighbors, metric=dtw_d_metric_, algorithm='brute')\n",
    "\n",
    "    knn_dependent_dtw_.fit(data_training['dtw_data'], data_training['training_labels'])\n",
    "    print \"fit done..\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    predictions_d = knn_dependent_dtw_.predict(data_test['dtw_data'])\n",
    "    dtw_d_results['total_time'].append(time.time() - start_time)\n",
    "    print \"predict done..\"\n",
    "    \n",
    "    dtw_d_results = evaluate_classification_performance_(data_test['test_labels'], predictions_d, dtw_d_results)\n",
    "\n",
    "    print \"evaluation done..\"\n",
    "    start_time = time.time()\n",
    "    prediction = knn_dependent_dtw_.predict(data_test['dtw_data'][:1])\n",
    "    dtw_d_results['time_one_sample'].append(time.time() - start_time)\n",
    "        \n",
    "    \n",
    "    # independent DTW\n",
    "    print \"------ DTW i\"\n",
    "    knn_independent_dtw_ = KNeighborsClassifierWrapper(n_neighbors=neighbors, metric=dtw_i_metric_, algorithm='brute')\n",
    "\n",
    "    knn_independent_dtw_.fit(data_training['dtw_data'], data_training['training_labels'])\n",
    "    print \"fit done..\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions_i = knn_independent_dtw_.predict(data_test['dtw_data'])\n",
    "    dtw_i_results['total_time'].append(time.time() - start_time)\n",
    "    print \"predict done..\"\n",
    "    \n",
    "    dtw_i_results = evaluate_classification_performance_(data_test['test_labels'], predictions_i, dtw_i_results)\n",
    "    \n",
    "    print \"evaluation done..\"\n",
    "    start_time = time.time()\n",
    "    prediction = knn_independent_dtw_.predict(data_test['dtw_data'][:1])\n",
    "    dtw_i_results['time_one_sample'].append(time.time() - start_time)\n",
    "    \n",
    "    \n",
    "    #\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_d_results_mean = dict()\n",
    "dtw_d_results_std = dict()\n",
    "dtw_i_results_mean = dict()\n",
    "dtw_i_results_std = dict()\n",
    "\n",
    "for key, value in dtw_d_results.items():\n",
    "    if key == 'confusion_matrix':\n",
    "        dtw_d_results_mean[key] = np.mean(value, axis=0)\n",
    "        dtw_d_results_std[key] = np.std(value, axis=0)\n",
    "    else: \n",
    "        dtw_d_results_mean[key] = np.mean(value)\n",
    "        dtw_d_results_std[key] = np.std(value)\n",
    "\n",
    "for key, value in dtw_i_results.items():\n",
    "    if key == 'confusion_matrix':\n",
    "        dtw_i_results_mean[key] = np.mean(value, axis=0)\n",
    "        dtw_i_results_std[key] = np.std(value, axis=0)\n",
    "    else: \n",
    "        dtw_i_results_mean[key] = np.mean(value)\n",
    "        dtw_i_results_std[key] = np.std(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = dict()\n",
    "\n",
    "\n",
    "all_results['dtw_d_mean'] = dtw_d_results_mean\n",
    "all_results['dtw_d_std'] = dtw_d_results_std\n",
    "all_results['dtw_i_mean'] = dtw_i_results_mean\n",
    "all_results['dtw_i_std'] = dtw_i_results_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results = pd.DataFrame(all_results)\n",
    "df_all_results.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Berndt, D. J., & Clifford, J. (1994, July). Using dynamic time warping to find patterns in time series. In KDD workshop (Vol. 10, No. 16, pp. 359-370).\n",
    "Bagnall, A., Bostrom, A., Large, J., & Lines, J. (2016). The great time series classification bake off: An experimental evaluation of recently proposed algorithms. extended version. arXiv preprint arXiv:1602.01711.\n",
    "\n",
    "[2] Salvador, S., & Chan, P. (2007). Toward accurate dynamic time warping in linear time and space. Intelligent Data Analysis, 11(5), 561-580.\n",
    "\n",
    "[3] Shokoohi-Yekta, M., Hu, B., Jin, H., Wang, J., & Keogh, E. (2017). Generalizing DTW to the multi-dimensional case requires an adaptive approach. Data mining and knowledge discovery, 31(1), 1-31."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
